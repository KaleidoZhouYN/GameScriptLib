{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d840cb4-5af8-475a-ac92-8362f180bef2",
   "metadata": {},
   "source": [
    "# train epic seven hero avator recognition network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1585f3a0-2fa2-4d5d-9037-e5866d3faf6b",
   "metadata": {},
   "source": [
    "## define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "657825d8-a87c-4d67-94cf-fc8ab3d418d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNet\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, class_num):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.conv2d()\n",
    "        self.conv2 = nn.conv2d()\n",
    "        self.conv3 = nn.conv2d()\n",
    "        self.fc = nn.adaptivePool2d(1,1)\n",
    "        self.cls = nn.Linear()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.fc(x)\n",
    "        cls = self.cls(x)\n",
    "        return cls\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f187e2-32dd-41b1-9dac-a6defe7752f6",
   "metadata": {},
   "source": [
    "## define dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f86ea3e-b13b-4565-8650-ad2bc115a339",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m         img[sy:sy\u001b[38;5;241m+\u001b[39mr_h,sx:sx\u001b[38;5;241m+\u001b[39mr_w] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class RandomFlip:\n",
    "    def __init__(self, rate=0.5):\n",
    "        self.rate = rate\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > self.rate:\n",
    "            return img\n",
    "        return np.flip(img,0)\n",
    "\n",
    "class RandomOcc:\n",
    "    def __init__(self, rate = 0.5):\n",
    "        self.rate = rate\n",
    "        self.blocksize = 10\n",
    "\n",
    "    def __call__(self,img):\n",
    "        if random.random() > self.rate:\n",
    "            return img\n",
    "        h,w,_  = img.shape\n",
    "        r_w = random.randint(1, self.blocksize)\n",
    "        r_h = random.randint(1, self.blockszie)\n",
    "        sx = random.randint(0, w-r_w-1)\n",
    "        sy = random.randint(0, h-r_h-1)\n",
    "        img[sy:sy+r_h,sx:sx+r_w] = 0\n",
    "        return img\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0ab781-2269-4a1b-a301-d64973b3ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset():\n",
    "    def __init__(self, folder):\n",
    "        self.folder = folder\n",
    "        self.num = len(os.listdir(folder))\n",
    "        self.filenames = os.listdir(folder)\n",
    "        self.map_name2id = {}\n",
    "        self.map_id2name = {}\n",
    "        cnt = 0\n",
    "        for filename in self.filenames:\n",
    "            id = filename.split('.')[0].split('_')[0]\n",
    "            self.map_name2id[id] = cnt\n",
    "            self.map_id2name[str(cnt)] = id\n",
    "            cnt += 1\n",
    "\n",
    "        self.transforms = [RandomFlip(), RandomOcc, torchvison.transforms.ToTensor()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.filenames[index]\n",
    "        id = filename.split('.')[0].split('_')[0]\n",
    "        path = os.path.join(self.folder, filename)\n",
    "        img = cv2.imread(path)\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        label = self.map_name2id[id]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d7022-2af4-4acd-a016-f7b4ff363cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
